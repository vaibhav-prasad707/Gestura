# Gestura âœ‹ğŸ’¬

**Gestura** is a multi-modal assistive communication platform designed to enhance accessibility through gesture recognition, voice interaction, and real-time communication features. It integrates sign language detection, a voice assistant, a responsive frontend interface, and video conferencing support.

---

## ğŸŒŸ Features

- **Sign Language Detection**
  - Detects hand gestures using a webcam and maps them to alphabetic characters or words.
  - Helps convert sign language into readable text or audible voice.

- **Voice Assistant**
  - Converts spoken commands or speech into text using speech recognition.
  - Acts as a voice-based input tool for accessible interaction.

- **Accessible Chat Interface**
  - Frontend built using HTML, CSS, and JavaScript.
  - Contains features for easy chat, interaction, and navigation.

- **Login & Authentication**
  - Basic user authentication system to manage sessions (available in ZIP format).

- **Video Conferencing**
  - Supports real-time video communication.
  - Ideal for remote accessibility or virtual assistance.

---

To run the backend Python components, you may need the following packages:

- Python 3.8+
- OpenCV (`cv2`)
- SpeechRecognition
- PyAudio
- Flask (optional for integration)

---

## ğŸ‘¨â€ğŸ’» Contributors

- [Vaibhav Prasad](https://github.com/vaibhav-prasad707)
- [adisraj](https://github.com/adisraj)
- [ishaanpearpie](https://github.com/ishaanpearpie)
- [Brian Thomas Mathew](https://github.com/brian-t-mathew)

---

## ğŸ“„ License

This project is currently unlicensed. Please contact the contributors if you would like to use or extend any part of the project.

---

## ğŸ“¬ Contact

For collaborations, improvements, or questions, feel free to connect with the contributors through GitHub.

